{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Import-modules\" data-toc-modified-id=\"Import-modules-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import modules</a></span></li><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load dataset</a></span></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Logarithmic-loss\" data-toc-modified-id=\"Logarithmic-loss-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Logarithmic loss</a></span></li><li><span><a href=\"#Area-Under-ROC-Curve\" data-toc-modified-id=\"Area-Under-ROC-Curve-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Area Under ROC Curve</a></span></li><li><span><a href=\"#Confusion-matrix\" data-toc-modified-id=\"Confusion-matrix-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Confusion matrix</a></span></li><li><span><a href=\"#Classification-report\" data-toc-modified-id=\"Classification-report-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Classification report</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Classification metrics\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (768, 9)\n"
     ]
    }
   ],
   "source": [
    "filename = \"../../DATASETS/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \n",
    "dataframe = read_csv(filename, names = names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "print(\"Data shape: \", dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- We are going to see the following metrics\"\n",
    "    - [1] Classification Accuracy\n",
    "    - [2] Logarithmic Loss\n",
    "    - [3] Area Under ROC Curve\n",
    "    - [4] Confusion Matrix\n",
    "    - [5] Classification Report\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "-  Classification ACCURACY is the number of correct predictions made as a ratio of all predictions made. \n",
    "\n",
    "- **CONS**: it is also the most misused. It is really only  suitable when there are an equal number of observations in each class \n",
    "(which is rarely the case) and that all predictions and prediction errors  are equally important, which is often not the case\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.7721633629528366  with standard deviation 0.0496837651757489\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 7)\n",
    "model = LogisticRegression(max_iter = 250)\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'accuracy') \n",
    "print(\"Classification accuracy: \", results.mean(), \" with standard deviation\", results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Logarithmic loss (or logloss) is a performance metric for evaluating the predictions  of probabilities of membership to a given class. \n",
    "- The scalar probability between  0 and 1 can be seen as a measure of confidence for a prediction by an algorithm. \n",
    "\n",
    "- The smaller the better. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  -0.48539951199731746  with standard deviation 0.05662123663545986\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 7)\n",
    "model = LogisticRegression(max_iter = 250)\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_log_loss') \n",
    "print(\"Classification accuracy: \", results.mean(), \" with standard deviation\", results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Area under ROC Curve (or AUC for short) is a performance metric for  binary classification problems. The AUC represents a modelâ€™s ability\n",
    "to discriminate between positive and negative classes. An area of 1.0  represents a model that made all predictions perfectly. An area of 0.5\n",
    "represents a model that is as good as random. ROC can be broken down  into sensitivity and specificity.\n",
    "\n",
    "- SENSITIVITY is the true positive rate also called the recall.  It is the number of instances from the positive (first) class  that actually predicted correctly.\n",
    "\n",
    "- SPECIFICITYT is also called the true negative rate. Is the number of  instances from the negative (second) class that were actually predicted correctly. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.8294519275727007  with standard deviation 0.046996783036400036\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "model = LogisticRegression(max_iter=250)\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring='roc_auc')\n",
    "print(\"Classification accuracy: \", results.mean(),\n",
    "      \" with standard deviation\", results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- The confusion matrix is a handy presentation of the accuracy of a model with two or  more classes. The table presents predictions on the x-axis and accuracy outcomes on  the y-axis. \n",
    "- The cells of the table are the number of predictions made by a machine  learning algorithm. \n",
    "- For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. \n",
    "- Predictions for 0 that were actually 0 appear in the cell for prediction = 0 and actual = 0, whereas predictions  for 0 that were actually 1 appear in the cell for prediction = 0 and actual = 1. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 34  58]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAlthough the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions).\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(max_iter=250)\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions). \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- The scikit-learn library provides a convenience report when working on classification  problems to give you a quick idea of the accuracy of a model using a number of measures. \n",
    "- The classification report() function displays the precision, recall, F1-score and  support for each class. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       162\n",
      "         1.0       0.74      0.63      0.68        92\n",
      "\n",
      "    accuracy                           0.79       254\n",
      "   macro avg       0.78      0.75      0.76       254\n",
      "weighted avg       0.78      0.79      0.78       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "                                                    random_state=seed)\n",
    "model = LogisticRegression(max_iter=250)\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
