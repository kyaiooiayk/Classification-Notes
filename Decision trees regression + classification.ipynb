{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Decision tree\n",
    "\n",
    "An ensemble method prediction is composed of different machine learning models that combine to work together. \n",
    "The individual models that make up the ensemble are called base learners.\n",
    "Decision trees, the most commonly used base learners, are unique in the machine learning landscape. \n",
    "Instead of multiplying column values by numeric weights, as in linear regression and logistic regression \n",
    "decision trees split the data by asking questions about the columns.\n",
    "\n",
    "Corey Wade. “Hands-On Gradient Boosting with XGBoost and scikit-learn. \n",
    "https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_census = pd.read_csv('../DATASETS/census_cleaned.csv')\n",
    "\n",
    "# Split data into X and y\n",
    "X = df_census.iloc[:,:-1]\n",
    "y = df_census.iloc[:,-1]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131679154894976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize classification model\n",
    "clf = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Fit model on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bikes = pd.read_csv('../DATASETS/bike_rentals_cleaned.csv')\n",
    "\n",
    "# Split data into X and y\n",
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE mean: 1233.36\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree Regressor\n",
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "\n",
    "# Obtain scores of cross-validation using mean squared error\n",
    "scores = cross_val_score(reg, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Take square root of the scores\n",
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "# Display mean score\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The RMSE is 1233.36. This is worse than the 972.06 obtained from Linear Regression and from the 887.31 obtained by\n",
    "XGBoost. Is the model overfitting the data because the variance is too high? This question may be answered by seeing\n",
    "how well the decision tree makes predictions on the training set alone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and score DecisionTreeRegressor on training set\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_train)\n",
    "reg_mse = mean_squared_error(y_train, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A RMSE of 0.0 means that the model has perfectly fit every data point! This perfect score combined with a \n",
    "cross-validation error of 1233.36 is proof that the decision tree is overfitting the data with high variance. \n",
    "The training set fit perfectly, but the test set missed badly.\n",
    "\n",
    "Solutions? Hyperparameters may rectify the situation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression -> hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generally speaking, decreasing max hyperparameters and increasing min hyperparameters will reduce variation\n",
    "and prevent overfitting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# Choose max_depth hyperparameters\n",
    "params = {'max_depth':[None,2,3,4,6,8,10,20]}\n",
    "\n",
    "# Initialize regression model as reg\n",
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "\n",
    "# Initialize GridSearchCV as grid_reg\n",
    "grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit grid_reg on X_train and y_train\n",
    "grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# Extract best parameters\n",
    "best_params = grid_reg.best_params_\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As you can see, a max_depth value of 6 resulted in the best cross-validation score in the training set.\n",
    "Remember this is done through cross-validation, the result are the mean of the results and this gives\n",
    "a better estimate of the error.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 951.173\n"
     ]
    }
   ],
   "source": [
    "# Compute best score\n",
    "best_score = np.sqrt(-grid_reg.best_score_)\n",
    "\n",
    "# Print best score\n",
    "print(\"Training score: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 864.670\n"
     ]
    }
   ],
   "source": [
    "# Extract best model\n",
    "best_model = grid_reg.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variance has been dsubstantially reduced.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid_search function\n",
    "def grid_search(params, reg=DecisionTreeRegressor(random_state=2)):\n",
    "\n",
    "    # Instantiate GridSearchCV as grid_reg\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best params\n",
    "    best_params = grid_reg.best_params_\n",
    "\n",
    "    # Print best params\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    # Compute best score\n",
    "    best_score = np.sqrt(-grid_reg.best_score_)\n",
    "\n",
    "    # Print best score\n",
    "    print(\"Training score: {:.3f}\".format(best_score))\n",
    "\n",
    "    # Predict test set labels\n",
    "    y_pred = grid_reg.predict(X_test)\n",
    "\n",
    "    # Compute rmse_test\n",
    "    rmse_test = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "    # Print rmse_test\n",
    "    print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the training samples\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_leaf': 8}\n",
      "Training score: 895.859\n",
      "Test score: 855.620\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "Training score: 870.381\n",
      "Test score: 913.000\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[None,2,3,4,6,8,10,20],'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The result may be a surprise. Even though the training score has improved, the test score has not. min_samples_leaf \n",
    "has decreased from 8 to 2, while max_depth has remained the same.\n",
    "This is a valuable lesson in hyperparameter tuning: Hyperparameters should not be chosen in isolation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 9, 'min_samples_leaf': 7}\n",
      "Training score: 888.787\n",
      "Test score: 878.538\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[5,6,7,8,9],'min_samples_leaf':[3,5,7,9]})"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
